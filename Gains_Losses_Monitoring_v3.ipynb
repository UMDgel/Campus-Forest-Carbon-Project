{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAcFwbuvDoVl"
      },
      "outputs": [],
      "source": [
        "#To set up your workspace, use your specified filepath\n",
        "#Be sure to change all directory and file names to your own"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Permit Google Colab to access files in google drive\n",
        "#Can either (1) mount using the following line of code or (2) set manually in left hand 'Files' panel if using Google Colaboratory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dgKjFlIuD1xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install packages \n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "!pip install rasterstats\n",
        "!pip install rioxarray"
      ],
      "metadata": {
        "id": "fAyp112VD76i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "##Must be run each time session is started\n",
        "import glob \n",
        "import os \n",
        "import ogr\n",
        "import gdal, gdalconst \n",
        "\n",
        "import rasterio as rio\n",
        "from rasterio.plot import show\n",
        "import rasterstats \n",
        "import rioxarray\n",
        "import xarray\n",
        "from shapely.geometry import mapping\n",
        "\n",
        "import numpy as np \n",
        "import geopandas as gpd \n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "904pO69jEAUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre 2016 Monitoring"
      ],
      "metadata": {
        "id": "kyuI-hKkLcHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is recommended to make two folders; Pre 2016 and Post 2016"
      ],
      "metadata": {
        "id": "YPGgqYZoLS4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_moni = '/content/drive/my_file_path/' ## File path of all data\n",
        "\n",
        "### Here define filename needed for following analysis\n",
        "Project_shp = os.path.join(filepath_moni, 'ProjectBoundary.shp') ## file path of boundary shapefile (Change ProjectBoundary accordingly)\n",
        "NAFD_file = os.path.join(filepath_moni,'NAFD_MD_1984_2016_albers_30m-001.tif') ##NAFD data, can be found in README, similar function to GFW\n",
        "AGB_prefix = os.path.join(filepath_moni,'AGB_Years/band') ## file prefix of AGB files which have original projection\n",
        "\n",
        "yrs = np.arange(2010,2016+1) ## years to calculate gain and loss; change if using a different time scale\n",
        "\n",
        "\n",
        "## Load Project shp as gpd\n",
        "Project_gpd = gpd.read_file(Project_shp)\n",
        "## Extract geometry for following clipping\n",
        "Project_geo = Project_gpd.geometry.apply(mapping)\n",
        "\n",
        "\n",
        "## Load NAFD\n",
        "NAFD_da = rioxarray.open_rasterio(NAFD_file)\n",
        "NAFD_da = NAFD_da.rename({'band':'time'}) ## change dimension name of 'band' to 'time'\n",
        "NAFD_da['time'] = range(1984,2016+1) ## assign time\n",
        "NAFD_da = NAFD_da.sel(time=yrs) ## select bands corresponding to yrs\n",
        "NAFD_da = NAFD_da.rio.clip(Project_geo,crs=Project_gpd.crs,drop=True) ## clip NAFD to project boundary\n",
        "\n",
        "\n",
        "## Load AGB for each of yrs\n",
        "AGB_da_list = [] # defining each raster's year \n",
        "for yr in yrs:\n",
        "  tmp_agb_da = rioxarray.open_rasterio('%s_%d.tif' % (AGB_prefix,yr)) ## Loading AGB for given year\n",
        "  tmp_agb_da = tmp_agb_da.where(tmp_agb_da >= -100) ## mask out no data value\n",
        "  tmp_agb_da = tmp_agb_da.rename({'band':'time'}) ## change dimension name of 'band' to 'time'\n",
        "  tmp_agb_da = tmp_agb_da.assign_coords({'time':[yr]}) ## assign time\n",
        "  tmp_agb_da = tmp_agb_da.interp(x=NAFD_da['x'].data,y=NAFD_da['y'].data) ## interpolate AGB to same coordinates of NAFD so that theya are align\n",
        "  tmp_agb_da = tmp_agb_da.rio.clip(Project_geo,crs=Project_gpd.crs,drop=True) ## clip NAFD to project domain\n",
        "  AGB_da_list.append(tmp_agb_da) ## append annual AGB to a list which will be concatenated latter\n",
        "  del tmp_agb_da\n",
        "\n",
        "AGB_ts_da = xr.concat(AGB_da_list,dim='time') ## concatenate agb of each individual years\n",
        "# 3 dimensions -> (time, x, y) with same coords as NAFD \n",
        "\n",
        "AGB_ts_da = AGB_ts_da.where(AGB_ts_da>=-100) ## re-mask, as clipping step change masked pixesl to some invalid values.\n",
        "del AGB_da_list ## remove temporary list to save RAM\n",
        "\n",
        "\n",
        "## for loop for calculating annual C change\n",
        "for yr in yrs:\n",
        "  if yr == yrs[0]: ## skip the first year as it does not have previous year\n",
        "    continue\n",
        "\n",
        "  ## calculate AGB difference/growth from last to current year\n",
        "  AGB_diff = AGB_ts_da.sel(time=yr) - AGB_ts_da.sel(time=yr-1) # can select specific time instead of indexing \n",
        "\n",
        "  ## load NAFD in last year and current year\n",
        "  nafd_cur_yr = NAFD_da.sel(time=yr)\n",
        "  nafd_lst_yr = NAFD_da.sel(time=yr-1)\n",
        "\n",
        "  ## define mask of pixels disburbed from last to current year\n",
        "  loss_mask = (nafd_lst_yr == 5) & (nafd_cur_yr == 7)\n",
        "  loss_mask = loss_mask | ((nafd_lst_yr == 5) & (nafd_cur_yr >= 100))\n",
        "\n",
        "  ## define mask of pixels recovered from last to current year\n",
        "  gain_mask = (nafd_lst_yr == 7) & (nafd_cur_yr == 5)\n",
        "  gain_mask = (nafd_lst_yr >= 100) & (nafd_cur_yr == 5)\n",
        "\n",
        "  ## define mask of pixels without disturbance and recovery\n",
        "  unchange_mask = ~loss_mask & ~gain_mask\n",
        "\n",
        "  ## calculate total carbon changes over given mask\n",
        "  c_loss_ttl = AGB_diff.where(loss_mask).sum().data*30*30/1e3\n",
        "  c_gain_ttl = AGB_diff.where(gain_mask).sum().data*30*30/1e3\n",
        "  c_unchange_ttl = AGB_diff.where(unchange_mask).sum().data*30*30/1e3\n",
        "\n",
        "  # dont need to reproject b/c pixel size is meter based \n",
        "\n",
        "  # print('%d %d %d %d %d' % (yr, unchange_mask.sum()+loss_mask.sum()+gain_mask.sum(), unchange_mask.sum(), loss_mask.sum(), gain_mask.sum()))\n",
        "  print('%d' % yr)\n",
        "  print('   loss %.2f Mg C, %d 30x30m pixels' % (c_loss_ttl,loss_mask.sum().data))\n",
        "  print('   regrowth %.2f Mg C, %d 30x30m pixels' % (c_gain_ttl,gain_mask.sum().data)) # regrowth \n",
        "  print('   continued growth %.2f Mg C, %d 30x30m pixels' % (c_unchange_ttl,unchange_mask.sum().data)) # continued growth \n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "id": "i2wx_TTaUBK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post 2016 Monitoring"
      ],
      "metadata": {
        "id": "mmlIuNt6N609"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1 - Open and load shapefile of specific property "
      ],
      "metadata": {
        "id": "HRFRJbn_OCUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/drive/my_file_path'\n",
        "boundary_shp = os.path.join(filepath, 'ProjectBoundary.shp') ## CHANGE to your boundary shapefile\n",
        "boundary_gpd = gpd.read_file(boundary_shp) # this layer is for CRS MATCHING\n",
        "boundary_geo = boundary_gpd.geometry.apply(mapping) # this layer is for CLIPPING\n",
        "\n",
        "### feel free to change variable names to something that makes more sense to you (ex. boundary_shp)\n",
        "### if you do change the variable name, make sure you're consistent (ex. boundary_shp -> boundary_gpd -> boundary_geo)"
      ],
      "metadata": {
        "id": "1fPpyvEXP1-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2 - Preprocessing "
      ],
      "metadata": {
        "id": "FgBYqw5SQPJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2a - Reproject GFW loss layer to match coordinate reference system (CRS) of carbon stock raster layer\n",
        "stock_17_file = os.path.join(filepath, 'AGB_Years/my_file_path/band_2017.tif')\n",
        "stock_17 = rioxarray.open_rasterio(stock_17_file).astype(np.float32)\n",
        "stock_17 = stock_17.where(stock_17 >= -100)\n",
        "\n",
        "### any carbon monitoring layer works since they all have same CRS, here we use the 2017 stock\n",
        "\n",
        "GFW_loss_raw_file = os.path.join(filepath, 'Hansen_GFC-2021-v1.9_lossyear_40N_080W.tif') #GFW data, can be found in README, similar function to NAFD\n",
        "GFW_loss_raw_da = rioxarray.open_rasterio(GFW_loss_raw_file)\n",
        "GFW_loss_raw_da = GFW_loss_raw_da.sel(x=slice(-80,-72),y=slice(40,35)).load()\n",
        "GFW_loss_reproj_da = GFW_loss_raw_da.rio.reproject_match(stock_17) \n",
        "GFW_loss_reproj_da = GFW_loss_reproj_da.where(GFW_loss_reproj_da<255)\n",
        "\n",
        "# STEP 2b - Clip each layer to match extent of property \n",
        "GFW_loss_reproj_da = GFW_loss_reproj_da.rio.clip(boundary_geo,crs=boundary_gpd.crs) ## CHANGE to name of property variable -> boundary_geo and boundary_gpd are TWO different things, be mindful (see above)\n",
        "GFW_loss_reproj_da = GFW_loss_reproj_da.where(GFW_loss_reproj_da<255).where(GFW_loss_reproj_da>0)\n",
        "GFW_loss_reproj_da.rio.to_raster(os.path.join(filepath, 'LossPreprocess/ProjectBoundary_loss_preprocess.tif')) ## RENAME file with boundary name (i.e., replace 'ProjectBoundary' in 'ProjectBoundary_loss_preprocess.tif')\n",
        "\n",
        "### the last line of code will save a new GFW layer that has the same CRS and extent of your specific property\n",
        "### take note of where you save this layer! You can create a specific folder like I did to store it (GFW is the new folder I created)"
      ],
      "metadata": {
        "id": "QmlG9WvUQPj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3 - Calculation\n",
        "\n",
        "# open newly created GFW loss file of that specific property (ex. ProjectBoundary_loss_preprocess.tif) \n",
        "GFW_loss_file = os.path.join(filepath, 'LossPreprocess/ProjectBoundary_loss_preprocess.tif') ## CHANGE to name of your file \n",
        "GFW_loss = rioxarray.open_rasterio(GFW_loss_file)\n",
        "GFW_loss = GFW_loss.where(GFW_loss >= -100)\n",
        "GFW_loss += 2000\n",
        "\n",
        "# open 2017-2020 carbon stock files\n",
        "filepath_post = '/content/drive/my_file_path/AGB_Years/Post2016' #change to exact version of filepath\n",
        "data = glob.glob(os.path.join(filepath_post, '*.tif')) \n",
        "\n",
        "for i, data_path in enumerate(data):\n",
        "  raster = rioxarray.open_rasterio(data_path).astype(np.float32)\n",
        "  raster = raster.where(raster >= -100)\n",
        "  year = int(os.path.splitext(os.path.split(data_path)[1])[0][5:13])\n",
        "  loss_pixels = (GFW_loss == year)\n",
        "  stock_loss_year = raster.where(loss_pixels).sum().data*900/1e3\n",
        "  print(year, ':', stock_loss_year) "
      ],
      "metadata": {
        "id": "LGtC15drQRdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### See ED_Version Comparison sheet for 2017-2020 loss values for answer key "
      ],
      "metadata": {
        "id": "F8dTU0zjQbge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}